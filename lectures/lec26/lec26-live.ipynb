{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Set up packages for lecture. Don't worry about understanding this code, but\n",
    "# make sure to run it if you're following along.\n",
    "import numpy as np\n",
    "import babypandas as bpd\n",
    "import pandas as pd\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "%reload_ext pandas_tutor\n",
    "%set_pandas_tutor_options {'projectorMode': True}\n",
    "set_matplotlib_formats(\"svg\")\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.set_option(\"display.max_rows\", 7)\n",
    "pd.set_option(\"display.max_columns\", 8)\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "def standard_units(any_numbers):\n",
    "    \"Convert a sequence of numbers to standard units.\"\n",
    "    return (any_numbers - any_numbers.mean()) / np.std(any_numbers)\n",
    "\n",
    "def standardize(df):\n",
    "    \"\"\"Return a DataFrame in which all columns of df are converted to standard units.\"\"\"\n",
    "    df_su = bpd.DataFrame()\n",
    "    for column in df.columns:\n",
    "        df_su = df_su.assign(**{column + ' (su)': standard_units(df.get(column))})\n",
    "    return df_su\n",
    "\n",
    "# All of the following code is for visualization.\n",
    "def plot_regression_line(df, x, y, margin=0.02, alpha=1):\n",
    "    '''Computes the slope and intercept of the regression line between columns x and y in df (in original units) and plots it.'''\n",
    "    m = slope(df, x, y)\n",
    "    b = intercept(df, x, y)\n",
    "    \n",
    "    df.plot(kind='scatter', x=x, y=y, figsize=(10, 5), label='original data', alpha=alpha)\n",
    "    left = df.get(x).min()*(1 - margin)\n",
    "    right = df.get(x).max()*(1 + margin)\n",
    "    domain = np.linspace(left, right, 10)\n",
    "    plt.plot(domain, m*domain + b, color='purple', label='regression line')\n",
    "    plt.suptitle(format_equation(m, b), fontsize=18)\n",
    "    plt.legend();\n",
    "    \n",
    "# Just for visual purposes\n",
    "def format_equation(m, b):\n",
    "    if b > 0:\n",
    "        return r'$y = %.2fx + %.2f$' % (m, b)\n",
    "    elif b == 0:\n",
    "        return r'$y = %.2fx' % m\n",
    "    else:\n",
    "        return r'$y = %.2fx %.2f$' % (m, b)\n",
    "    \n",
    "# Don't worry about how this function works.\n",
    "def plot_errors(df, m, b, x_col='x', y_col='y'):\n",
    "    x = df.get(x_col)\n",
    "    y = m*x + b\n",
    "    df.plot(kind='scatter', x=x_col, y=y_col, figsize=(10, 5), label='original data')\n",
    "    plt.plot(x, y, color='purple', label='regression line')\n",
    "    for k in np.arange(df.shape[0]):\n",
    "        xk = df.get(x_col).iloc[k]\n",
    "        yk = np.asarray(y)[k]\n",
    "        if k == df.shape[0] - 1:\n",
    "            plt.plot([xk, xk], [yk, df.get(y_col).iloc[k]], '--', c='r', linewidth=2, label='errors')\n",
    "        else:\n",
    "            plt.plot([xk, xk], [yk, df.get(y_col).iloc[k]], '--', c='r', linewidth=2)\n",
    "    \n",
    "    plt.suptitle(format_equation(m, b), fontsize=18)\n",
    "    plt.xlim(50, 90)\n",
    "    plt.ylim(40, 100)\n",
    "    plt.legend();\n",
    "    \n",
    "def update_plot(w):\n",
    "    m = slope_widget.value\n",
    "    b = galton.get('childHeight').mean() - m * galton.get('midparentHeight').mean()\n",
    "    with out:\n",
    "        out.clear_output(wait=True)\n",
    "        plot_errors(galton, m, b, x_col='childHeight', y_col='midparentHeight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 26 ‚Äì Residuals and Inference\n",
    "\n",
    "## DSC 10, Summer 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    "- Lab 8 is due **tomorrow at 11:59pm**.\n",
    "- The Final Project is due **Wednesday at 11:59pm**\n",
    "    - To use a slip day, you and your partner both need to have one remaining.\n",
    "- The Final Exam is on **Saturday, 9/3 from 11:30am-2:30pm**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- Residuals.\n",
    "- Inference for regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quality of fit\n",
    "\n",
    "- The regression line describes the \"best linear fit\" for a given dataset.\n",
    "- The formulas for the slope and intercept work no matter what the shape of the data is.\n",
    "- But the line is only meaningful if the relationship between $x$ and $y$ is roughly linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Residuals\n",
    "\n",
    "- The errors of a regression line's predictions are called **residuals**.\n",
    "- There is one residual corresponding to each data point $(x, y)$ in the dataset.\n",
    "\n",
    "$$\\text{residual} = \\text{actual } y - \\text{predicted } y \\text{ by regression line}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Calculating residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def correlation(df, x, y):\n",
    "    '''Computes the correlation between column x and column y of df.'''\n",
    "    return (standard_units(df.get(x)) * standard_units(df.get(y))).mean()\n",
    "\n",
    "def slope(df, x, y):\n",
    "    '''Returns the slope of the regression line between columns x and y in df (in original units).'''\n",
    "    r = correlation(df, x, y)\n",
    "    return r * np.std(df.get(y)) / np.std(df.get(x))\n",
    "\n",
    "def intercept(df, x, y):\n",
    "    '''Returns the intercept of the regression line between columns x and y in df (in original units).'''\n",
    "    return df.get(y).mean() - slope(df, x, y) * df.get(x).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def fit(df, x, y):\n",
    "    ...\n",
    "    \n",
    "def residual(df, x, y):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predicting child height üë™ üìè\n",
    "\n",
    "- Is the association between `'midparentHeight'` and `'childHeight'` linear?\n",
    "    - If there is a linear association, is it strong?\n",
    "        - We can answer this using the correlation coefficient.\n",
    "        - Close to 0 = weak, close to -1/+1 = strong.\n",
    "    - Is \"linear\" the best description of the association between `'midparentHeight'` and `'childHeight'`?\n",
    "        - We'll use residuals to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galton = bpd.read_csv('data/galton.csv')\n",
    "\n",
    "heights = bpd.DataFrame().assign(\n",
    "    MidParent=galton.get('midparentHeight'),\n",
    "    Child=galton.get('childHeight')\n",
    ")\n",
    "\n",
    "fitted = heights.assign(\n",
    "    fit=...\n",
    "    residuals=...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_regression_line(fitted, 'MidParent', 'Child')\n",
    "\n",
    "idx = np.random.randint(0, fitted.shape[0], size=50)\n",
    "for i, k in enumerate(idx):\n",
    "    x = fitted.get('MidParent').iloc[k]\n",
    "    y = fitted.get('Child').iloc[k]\n",
    "    p = fitted.get('fit').iloc[k]\n",
    "    plt.plot([x,x], [y,p], '--', linewidth=3, color='red', label='residuals' if i==0 else None)\n",
    "plt.legend();\n",
    "print('Correlation:', correlation(galton, 'midparentHeight', 'childHeight'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The residual plot\n",
    "\n",
    "- The residual plot is the scatter plot with the original $x$ variable on the $x$ axis and residuals on the $y$ axis.\n",
    "- Residual plots describe how the error in the regression line's predictions varies.\n",
    "    $$\\text{residual} = \\text{actual } y - \\text{predicted } y \\text{ by regression line}$$\n",
    "    - If there is no pattern in the residual plot, it suggests that the linear fit is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reading the residual plot\n",
    "\n",
    "- If a linear fit is good, the residual plot:\n",
    "    - Should look like a patternless \"blob\".\n",
    "    - About half of the data points should be above the horizontal line at 0, and about half should be below.\n",
    "    - Should have similar vertical spread throughout.\n",
    "- What happens if these conditions aren't met?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The residual plot for a non-linear association üöó\n",
    "- Consider the hybrid cars dataset from earlier. \n",
    "- Let's look at a regression line that uses `'mpg'` to predict `'msrp'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid = bpd.read_csv('data/hybrid.csv')\n",
    "hybrid_fitted = hybrid.assign(\n",
    "    fit=fit(hybrid, 'mpg', 'msrp'),\n",
    "    residuals=residual(hybrid, 'mpg', 'msrp')\n",
    ")\n",
    "hybrid_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot of the original data and regression line\n",
    "plot_regression_line(hybrid, 'mpg', 'msrp');\n",
    "print('Correlation:', correlation(hybrid, 'mpg', 'msrp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Residual plot\n",
    "hybrid_fitted.plot(kind='scatter', x='fit', y='residuals', figsize=(10, 5), color='red', label='residuals')\n",
    "plt.axhline(0, color='k', label='y = 0')\n",
    "plt.title('Residual plot for regression between mpg and msrp')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that as `'mpg'` increases, the residuals go from being mostly large, to being mostly small, to being mostly large again. That's a pattern!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Issue #1: patterns in the residual plot\n",
    "\n",
    "- Patterns in the residual plot imply that the relationship between $x$ and $y$ may not be linear.\n",
    "    - While this can be spotted in the original scatter plot, it may be easier to identify in the residual plot.\n",
    "- In such cases, a curve may be a better choice than a line for prediction.\n",
    "    - You'll learn more about curve fitting in future courses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Another example: `'mpg'` and `'acceleration'` ‚õΩ\n",
    "\n",
    "- Let's fit a regression line to predict `'acceleration'` given `'mpg'`.\n",
    "- Let's then look at the resulting residual plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_mpg = hybrid.assign(\n",
    "    fit=fit(hybrid, 'acceleration', 'mpg'),\n",
    "    residuals=residual(hybrid, 'acceleration', 'mpg')\n",
    ")\n",
    "accel_mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot of the original data and regression line\n",
    "plot_regression_line(accel_mpg, 'acceleration', 'mpg')\n",
    "print('Correlation:', correlation(accel_mpg, 'acceleration', 'mpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Residual plot\n",
    "accel_mpg.plot(kind='scatter', x='fit', y='residuals', figsize=(10, 5), color='red', label='residuals')\n",
    "plt.axhline(0, color='k', label='y = 0')\n",
    "plt.title('Residual plot for regression between acceleration and msrp')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the residuals tend to vary more for smaller accelerations than they do for larger accelerations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Issue #2: uneven vertical spread\n",
    "\n",
    "- If the vertical spread in a residual plot is uneven, it implies that the regression line's predictions aren't equally accurate for all inputs.\n",
    "    - This doesn't necessarily mean that fitting a nonlinear curve would be better. It just impacts how we interpret the regression line's predictions.\n",
    "- The formal term for \"uneven spread\" is **heteroscedasticity**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Anscombe's quartet\n",
    "\n",
    "<center><img src='data/anscombe.png' width=800></center>\n",
    "\n",
    "- All 4 datasets have the same mean of $x$, mean of $y$, SD of $x$, SD of $y$, and correlation.\n",
    "    - Therefore, they have the same regression line because the slope and intercept of the regression line are determined by these quantities.\n",
    "- But they all look very different!\n",
    "- Not all of them are linearly associated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Another Example: The Datasaurus Dozen ü¶ñ\n",
    "\n",
    "[This dataset](https://www.autodesk.com/research/publications/same-stats-different-graphs) encourages you to \"never trust summary statistics alone; always visualize your data\"!\n",
    "\n",
    "<center><img src='data/datasaurus.png' width=800></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inference for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The regression model\n",
    "\n",
    "- Recall, a \"model\" is a set of assumptions about how data were generated.\n",
    "- The **regression model** states that the data in a scatter plot is generated by\n",
    "1. taking points on a perfectly straight \"true line\", and\n",
    "2. adding vertical \"noise\" to each point that has a mean of 0.\n",
    "- If the regression model is satisfied, then a dataset:\n",
    "    - is shaped like an oval, roughly around an \"invisible\" true line.\n",
    "    - has a residual plot with no patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Another perspective on regression\n",
    "\n",
    "- What we're really doing:\n",
    "    - Collecting a sample of data from a population.\n",
    "    - Fitting a regression line to that sample.\n",
    "    - Using that regression line to make predictions for inputs that are not in our sample.\n",
    "\n",
    "- What if we used a different sample? ü§î"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prediction intervals\n",
    "\n",
    "Approach:\n",
    "1. Bootstrap the sample.\n",
    "2. Compute the slope and intercept of the regression line for that sample.\n",
    "3. Repeat steps 1 and 2 many times to compute many slopes and many intercepts.\n",
    "4. Use the bootstrapped slopes and intercepts to create bootstrapped predictions, and take the middle 95% of them.\n",
    "\n",
    "This will give us a **prediction interval**, i.e. a range of reasonable values for a prediction for a single input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Resampling the scatter plot of parent/child heights\n",
    "\n",
    "Note that each time we run this cell, the resulting line is slighty different!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the dataset\n",
    "resampled = ...\n",
    "\n",
    "# Plot line of best fit\n",
    "plot_regression_line(resampled, 'MidParent', 'Child', alpha=0.5)\n",
    "\n",
    "plt.ylim([55, 80])\n",
    "plt.xlim([62, 77]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### You Try: Bootstrapping predictions: parent/child heights\n",
    "\n",
    "1. Take a bootstrap sample of `heights`. (Take a sample of the same size as `heights` with replacement.)\n",
    "1. Find the slope and intercept of the best-fit line on the resample. (Hint: Use functions that we've already defined.)\n",
    "1. Repeat 5,000 times. Keep track of the slopes in `boot_slopes` and the intercepts in `boot_intercepts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### If a midparent height is 74, what is the predicted child's height?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_value = 74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the original dataset, and hence the original slope and intercept, we get a single prediction for the input of 74."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_orig = m_orig * input_value + b_orig\n",
    "pred_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### You Try: Making a Prediction Interval\n",
    "\n",
    "1. Use `boot_slopes` and `boot_intercepts` to make bootstrapped predictions for the input of 74. Call this array `boot_preds`.\n",
    "1. Find a 95% confidence interval for the predictions by taking the 2.5th and 97.5th percentile of the predictions. Store the left endpoint in `l` and the right endpoint in `r`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_preds = ...\n",
    "boot_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ...\n",
    "r = ...\n",
    "[l, r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If all goes well, this cell should run\n",
    "bpd.DataFrame().assign(\n",
    "    predictions=boot_preds\n",
    ").plot(kind='hist', density=True, bins=20, figsize=(10, 5), ec='w')\n",
    "plt.plot([l,r],[0.01,0.01], c='lime', linewidth=8, zorder=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How different could our prediction have been, for all inputs?\n",
    "\n",
    "Here, we'll plot 20 of our bootstrapped lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Don't worry about the code for this.\n",
    "plt.figure(figsize=(10, 5))\n",
    "x = np.arange(58, 78)\n",
    "ys = []\n",
    "for (m,b) in zip(boot_slopes[:20], boot_intercepts):\n",
    "    ys.append(m * x + b)\n",
    "    plt.plot(x, m * x + b, linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 95% confidence interval for the regression line\n",
    "\n",
    "This plot shows a 95% confidence interval for where the \"true\" line lies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't worry about the code for this.\n",
    "all_lines = np.vstack(ys)\n",
    "upper = all_lines.max(axis=0)\n",
    "lower = all_lines.min(axis=0)\n",
    "\n",
    "# plot_regression_line(galton, 'midparentHeight', 'childHeight')\n",
    "plt.fill_between(x, upper, lower, alpha=.6, color='C0')\n",
    "plt.plot(x, m*x + b, color='purple');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why does it matter?\n",
    "\n",
    "- No use fitting a linear model for nonlinear data!\n",
    "    - Always need to plot the data before fitting.\n",
    "- Prediction intervals very useful!\n",
    "    - Can bootstrap data for almost any model to quantify model's uncertainty.\n",
    "\n",
    "### Next time\n",
    "\n",
    "- We'll review in class on Wednesday and Friday.\n",
    "- No new material after this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
